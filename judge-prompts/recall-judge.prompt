---
model: gpt-4o-2024-08-06
response_format:
  type: json_schema
  json_schema:
    schema:
      $defs:
        Answer:
          properties:
            statement:
              description: The statement to be judged.
              title: Statement
              type: string
            reason:
              description: The reason for the verdict.
              title: Reason
              type: string
            verdict:
              description: 1 if the statement can be directly inferred based on the
                ground_truth or 0 if the statement can not be directly inferred based
                on the ground_truth.
              title: Verdict
              type: integer
          required:
          - statement
          - reason
          - verdict
          title: Answer
          type: object
          additionalProperties: false
      properties:
        answer:
          description: The list of answers to be judged.
          items:
            $ref: '#/$defs/Answer'
          title: Answer
          type: array
      required:
      - answer
      title: RecallJudgeResponse
      type: object
      additionalProperties: false
    name: RecallJudgeResponse
    strict: true
---
<system>
Your task is to judge how many ground_truth_statements are included in prediction. For each ground_truth statement you must return verdict as 1 if the statement is included in prediction or 0 if the statement can not be found in prediction.
You can verdict as 1 if the statement is similar enough to the prediction, even if it is not an exact match.
Here are the discrepancies to look for:
    1) Numerical Accuracy:
        For numerical answers, if the absolute error from the statement is no more than 10% of the prediction, you should consider it is included and return: 1
        i) Here is example of "[prediction]" | "[statement]" pair that should be considered correct:
            "800 trees"      â”‚ "754" (because the error [abs(800 - 754) = 46)] is only 5.7% [46/800] of the prediction)
        ii) Here is example that should be considered not included since the error from the answer is more than 10%.
            "10%"       | "20%" (because the error [abs(10 - 20) = 10)] is 100% [10/10] of the prediction)
    2)  Date Accuracy:
        You can be lenient when it comes to date specification.
        i) Examples of correct assessments for dates:
        "July 2023"      |       "25th of July 2023"
        "12/12/1994"     |       "Dec, 1994"
        --
        your response should be: 1
        ii) Examples of incorrect assesments
        "July 2019"     |       "23/05/2019" (because July 2019 cannot pass as the same date for May 2019)
        your response should be: 0
    3) Lists:
        When comparing the statement for lists, except when a specific number of items is specified in a list, as far as the majority of items in both the prediction and the statement are the same, you can evaluate the statement is included.        
        i) Examples of correct assessments for list comparisons:
        "prediction : Founders of airtable are Howie Liu, Andrew Ofstad, Emmett Nicholas"    |   "statement: Founders of airtable are Howie Liu, Andrew Ofstad, and Emmett Nicholas" (because most names in both lists are the same, irrespective of order)
        Your Response for the above should be: 1 
        ii) Examples of incorrect assessments for list comparisons:
        "prediction : Top 3 players in the NFL are Michael James, Evander Holyfield, Emmet Shear"    |   "statement: Top 3 players in the NFL are Michael James, Evander Holyfield, John Boyega" (because it cares about ranking and only wants a specific list of 3, so even if two of the names are present, the last name is not correct)
        Your Response for the above should be: 0
        
The output should be a well-formatted JSON instance.

Below are some examples.

Prediction:
John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.

Ground Truth Statements:
["John is majoring in Biology.", "John is taking a course on Artificial Intelligence.", "John is a dedicated student.", "John has a part-time job."]

Answer:
{{"answer":[{{"statement": "John is majoring in Biology.", "reason": "The prediction states that John is pursuing a degree in Computer Science, not Biology.", "verdict": 0}}, {{"statement": "John is taking a course on Artificial Intelligence.", "reason": "The prediction lists the courses John is enrolled in: Data Structures, Algorithms, and Database Management. Artificial Intelligence is not mentioned.", "verdict": 0}}, {{"statement": "John is a dedicated student.", "reason": "The prediction states that John is a diligent student, spends a significant amount of time studying and completing assignments, and often stays late in the library. This indicates he is dedicated.", "verdict": 1}}, {{"statement": "John has a part-time job.", "reason": "The prediction does not mention anything about John having a part-time job.", "verdict": 0}}]}}

Prediction:
Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.

Ground Truth Statements:
["Albert Einstein was a genius."]

Answer:
{{"answer":[{{"statement": "Albert Einstein was a genius.", "reason": "The prediction is about photosynthesis and does not mention Albert Einstein or his intelligence.", "verdict": 0}}]}}
</system>
<user>
Prediction:
{prediction}

Ground Truth Statements:
{ground_truth_statements}

Answer:
</user>
